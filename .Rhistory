## ReadME
# Let's first write the function of getting mode:
Modes <- function(x) {
ux <- unique(x)
tab <- tabulate(match(x, ux))
ux[tab == max(tab)]
}
# note that if we are including interaction, by default it is FALSE to not include interaction
# effect between factors, set to TRUE manually if we are testing for
sim_data <- function(n, eff_size, alpha, interaction = FALSE) {
s <- eff_size/2 # how much each data is fluctuating around 0
f1 <- factor(sample(c("l1", "l2", "l3"), n, TRUE))
f2 <- factor(sample(c("l1", "l2"), n, TRUE))
f3 <- factor(sample(c("l1", "l2"), n, TRUE))
f4 <- factor(sample(c("l1", "l2"), n, TRUE))
f5 <- factor(sample(c("l1", "l2"), n, TRUE))
# prior generations at the level of eff_size, or in other words, standardized cohen's D
# distance,
mu_1 <- ifelse(f1 == 'l1', -1*s, ifelse(a == 'l2', 0, s))
mu_2 <- ifelse(f2 == 'l1', -1*s, s)
mu_3 <- ifelse(f3 == 'l1', -1*s, s)
mu_4 <- ifelse(f4 == 'l1', -1*s, s)
mu_5 <- ifelse(f5 == 'l1', -1*s, s)
mu <- cbind(mu_1, mu_2, mu_3, mu_4, mu_5)
# Now let us simulate the dat:
dv <- c()
for (i in 1:n){
dv[i] <- rnorm(1, mean(Modes(mu[i,])), 1)
# assume a standardeviation of 1 to follow the setup of  cohen's D
# People can change the mean of mode function to mode by writing their own, or median
}
# so far for model checking, I only check the case when some factor levels are significant, but see below by cases for a safer option (of which requires significant more sample size)
if (interaction == FALSE){
return(min(summary(lm(dv ~ f1 + f2 + f3 + f4 + f5))$coef[-1,4]) < alpha)
# coef[2,4] and coef[3,4] looks at the p-value of factor 1,
# as it is explored the least amount, we want to see if any level is significant
}
else{
return(min(summary(lm(dv~ f1 * f2 * f3 * f4 * f5))$coef[-1,4])< alpha)
# row 38:48 are all the five level interactions item,
# it is safe to show those are significant values
# (Fred made the assumption here, double check, what is your model design?)
}
}
## ReadME
# Let's first write the function of getting mode:
Modes <- function(x) {
ux <- unique(x)
tab <- tabulate(match(x, ux))
ux[tab == max(tab)]
}
# note that if we are including interaction, by default it is FALSE to not include interaction
# effect between factors, set to TRUE manually if we are testing for
sim_data <- function(n, eff_size, alpha, interaction = FALSE) {
s <- eff_size/2 # how much each data is fluctuating around 0
f1 <- factor(sample(c("l1", "l2", "l3"), n, TRUE))
f2 <- factor(sample(c("l1", "l2"), n, TRUE))
f3 <- factor(sample(c("l1", "l2"), n, TRUE))
f4 <- factor(sample(c("l1", "l2"), n, TRUE))
f5 <- factor(sample(c("l1", "l2"), n, TRUE))
# prior generations at the level of eff_size, or in other words, standardized cohen's D
# distance,
mu_1 <- ifelse(f1 == 'l1', -1*s, ifelse(a == 'l2', 0, s))
mu_2 <- ifelse(f2 == 'l1', -1*s, s)
mu_3 <- ifelse(f3 == 'l1', -1*s, s)
mu_4 <- ifelse(f4 == 'l1', -1*s, s)
mu_5 <- ifelse(f5 == 'l1', -1*s, s)
mu <- cbind(mu_1, mu_2, mu_3, mu_4, mu_5)
# Now let us simulate the dat:
dv <- c()
for (i in 1:n){
dv[i] <- rnorm(1, mean(Modes(mu[i,])), 1)
# assume a standardeviation of 1 to follow the setup of  cohen's D
# People can change the mean of mode function to mode by writing their own, or median
}
# so far for model checking, I only check the case when some factor levels are significant, but see below by cases for a safer option (of which requires significant more sample size)
if (interaction == FALSE){
return(min(summary(lm(dv ~ f1 + f2 + f3 + f4 + f5))$coef[-1,4]) < alpha)
# coef[2,4] and coef[3,4] looks at the p-value of factor 1,
# as it is explored the least amount, we want to see if any level is significant
}
else{
return(min(summary(lm(dv~ f1 * f2 * f3 * f4 * f5))$coef[-1,4])< alpha)
# row 38:48 are all the five level interactions item,
# it is safe to show those are significant values
# (Fred made the assumption here, double check, what is your model design?)
}
}
# it takes the mean value for the number of times the model is signifcant in the safest way when a rep number of data we simulated
get_power <- function(n, eff_size, reps, alpha, interaction = FALSE) {
mean(
sapply(1:reps, function(placeholder) {
sim_data(n, eff_size, alpha, interaction)
})
)
}
power_analysis <- function(eff_size, reps, start, end, by, alpha, interaction = FALSE) {
set.seed(447447539) # oh I have good ways finding seed, see if you can crack the mistery
out <- lapply(
seq(start, end, by),
get_power,
eff_size, reps, alpha, interaction
)
out <- as.data.frame(do.call(rbind, out))
names(out) <- "Interaction Term Power"
out$`Sample Size` <- seq(start, end, by)
return(
out[, c(2, 1)]
)
}
power_analysis(eff_size = 0.2,
reps = 1000,
start = 600,
end = 800,
by = 25,
alpha = 0.05,
interaction = FALSE)
## ReadME
# Let's first write the function of getting mode:
Modes <- function(x) {
ux <- unique(x)
tab <- tabulate(match(x, ux))
ux[tab == max(tab)]
}
# note that if we are including interaction, by default it is FALSE to not include interaction
# effect between factors, set to TRUE manually if we are testing for
sim_data <- function(n, eff_size, alpha, interaction = FALSE) {
s <- eff_size/2 # how much each data is fluctuating around 0
f1 <- factor(sample(c("l1", "l2", "l3"), n, TRUE))
f2 <- factor(sample(c("l1", "l2"), n, TRUE))
f3 <- factor(sample(c("l1", "l2"), n, TRUE))
f4 <- factor(sample(c("l1", "l2"), n, TRUE))
f5 <- factor(sample(c("l1", "l2"), n, TRUE))
# prior generations at the level of eff_size, or in other words, standardized cohen's D
# distance,
mu_1 <- ifelse(f1 == 'l1', -1*s, ifelse(f1 == 'l2', 0, s))
mu_2 <- ifelse(f2 == 'l1', -1*s, s)
mu_3 <- ifelse(f3 == 'l1', -1*s, s)
mu_4 <- ifelse(f4 == 'l1', -1*s, s)
mu_5 <- ifelse(f5 == 'l1', -1*s, s)
mu <- cbind(mu_1, mu_2, mu_3, mu_4, mu_5)
# Now let us simulate the dat:
dv <- c()
for (i in 1:n){
dv[i] <- rnorm(1, mean(Modes(mu[i,])), 1)
# assume a standardeviation of 1 to follow the setup of  cohen's D
# People can change the mean of mode function to mode by writing their own, or median
}
# so far for model checking, I only check the case when some factor levels are significant, but see below by cases for a safer option (of which requires significant more sample size)
if (interaction == FALSE){
return(min(summary(lm(dv ~ f1 + f2 + f3 + f4 + f5))$coef[-1,4]) < alpha)
# coef[2,4] and coef[3,4] looks at the p-value of factor 1,
# as it is explored the least amount, we want to see if any level is significant
}
else{
return(min(summary(lm(dv~ f1 * f2 * f3 * f4 * f5))$coef[-1,4])< alpha)
# row 38:48 are all the five level interactions item,
# it is safe to show those are significant values
# (Fred made the assumption here, double check, what is your model design?)
}
}
# it takes the mean value for the number of times the model is signifcant in the safest way when a rep number of data we simulated
get_power <- function(n, eff_size, reps, alpha, interaction = FALSE) {
mean(
sapply(1:reps, function(placeholder) {
sim_data(n, eff_size, alpha, interaction)
})
)
}
power_analysis <- function(eff_size, reps, start, end, by, alpha, interaction = FALSE) {
set.seed(447447539) # oh I have good ways finding seed, see if you can crack the mistery
out <- lapply(
seq(start, end, by),
get_power,
eff_size, reps, alpha, interaction
)
out <- as.data.frame(do.call(rbind, out))
names(out) <- "Interaction Term Power"
out$`Sample Size` <- seq(start, end, by)
return(
out[, c(2, 1)]
)
}
power_analysis(eff_size = 0.2,
reps = 1000,
start = 600,
end = 800,
by = 25,
alpha = 0.05,
interaction = FALSE)
power_analysis(eff_size = 0.2,
reps = 200,
start = 1000,
end = 1200,
by = 25,
alpha = 0.05,
interaction = FALSE)
power_analysis(eff_size = 0.2,
reps = 200,
start = 1200,
end = 1400,
by = 25,
alpha = 0.05,
interaction = FALSE)
power_analysis(eff_size = 0.2,
reps = 200,
start = 1300,
end = 1500,
by = 25,
alpha = 0.05,
interaction = FALSE)
power_analysis(eff_size = 0.5,
reps = 200,
start = 200,
end = 400,
by = 25,
alpha = 0.05,
interaction = FALSE)
power_analysis(eff_size = 0.5,
reps = 200,
start = 100,
end = 300,
by = 25,
alpha = 0.05,
interaction = FALSE)
power_analysis(eff_size = 0.8,
reps = 200,
start = 100,
end = 300,
by = 25,
alpha = 0.05,
interaction = FALSE)
power_analysis(eff_size = 0.8,
reps = 200,
start = 50,
end = 200,
by = 25,
alpha = 0.05,
interaction = FALSE)
power_analysis(eff_size = 0.2,
reps = 200,
start = 1300,
end = 1500,
by = 25,
alpha = 0.05,
interaction = TRUE)
power_analysis(eff_size = 0.2,
reps = 200,
start = 1500,
end = 1700,
by = 25,
alpha = 0.05,
interaction = TRUE)
power_analysis(eff_size = 0.2,
reps = 200,
start = 1800,
end = 2000,
by = 25,
alpha = 0.05,
interaction = TRUE)
power_analysis(eff_size = 0.2,
reps = 200,
start = 2000,
end = 2200,
by = 25,
alpha = 0.05,
interaction = TRUE)
power_analysis(eff_size = 0.5,
reps = 200,
start = 200,
end = 400,
by = 25,
alpha = 0.05,
interaction = TRUE)
power_analysis(eff_size = 0.5,
reps = 200,
start = 300,
end = 500,
by = 25,
alpha = 0.05,
interaction = TRUE)
power_analysis(eff_size = 0.5,
reps = 200,
start = 400,
end = 600,
by = 25,
alpha = 0.05,
interaction = TRUE)
power_analysis(eff_size = 0.8,
reps = 200,
start = 200,
end = 400,
by = 25,
alpha = 0.05,
interaction = TRUE)
power_analysis(eff_size = 0.2,
reps = 200,
start = 2000,
end = 2200,
by = 25,
alpha = 0.05,
interaction = TRUE)
power_analysis(eff_size = 0.5,
reps = 200,
start = 400,
end = 600,
by = 25,
alpha = 0.05,
interaction = TRUE)
power_analysis(eff_size = 0.8,
reps = 200,
start = 200,
end = 400,
by = 25,
alpha = 0.05,
interaction = TRUE)
